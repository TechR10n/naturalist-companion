{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Agentic Wikipedia Proof-of-Concept (Vertex AI Edition)\n",
    "\n",
    "Welcome to a short roadside pull-off on the information highway. Today’s trip is simple: pick a narrow topic, collect a few Wikipedia pages, embed them with Vertex AI, and see whether retrieval puts the right pages in the passenger seat before the model starts talking.\n",
    "\n",
    "This notebook mirrors `docs/agentic_wikipedia_gcp_spec.md`, but with extra signposts for incremental development. Keep the knobs small at first (e.g., `WIKIPEDIA_MAX_DOCS=5`), then widen the map once the pipeline runs end-to-end.\n",
    "\n",
    "## Data Source (what we’re picking up)\n",
    "\n",
    "`WikipediaLoader` ingests documents from the Wikipedia API and converts them into LangChain `Document` objects. The page content typically includes the first sections of an article, and each document comes with metadata you can use for grounding and citations.\n",
    "\n",
    "**Recommendation**: Filter down to a manageable slice (often **10k or fewer** documents), then expand only if retrieval quality needs it.\n",
    "\n",
    "In the metadata of each document, you’ll see:\n",
    "\n",
    "| Column  | Definition |\n",
    "|---------|------------|\n",
    "| title   | The Wikipedia page title (e.g., \"Quantum Computing\"). |\n",
    "| summary | A short extract or condensed description from the page content. |\n",
    "| source  | The URL link to the original Wikipedia article. |\n"
   ],
   "id": "4270543c0da2419b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Notebook Setup (Install Dependencies)\n",
    "\n",
    "# If you're running this notebook locally from the repo root:\n",
    "# %pip install -U -qqqq -r requirements.txt\n",
    "# %pip install -U -qqqq -r requirements-dev.txt\n",
    "#\n",
    "# Optional (FAISS vector store):\n",
    "# %pip install -U -qqqq -r requirements-faiss.txt\n"
   ],
   "id": "fe1576aaa8266897",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Python Package Imports (Reference)\n",
    "\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "from langchain_google_vertexai import ChatVertexAI, VertexAIEmbeddings\n",
    "import vertexai\n",
    "\n",
    "# Vector stores\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "try:\n",
    "    from langchain_community.vectorstores import FAISS\n",
    "    _HAS_FAISS = True\n",
    "except Exception:\n",
    "    _HAS_FAISS = False\n"
   ],
   "id": "6fc65ff997b9e3c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Vertex AI Initialization\n",
    "\n",
    "import os\n",
    "\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\", \"your-project-id\")\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_LOCATION\", \"us-central1\")\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "# **Advice**: Ensure `aiplatform.googleapis.com` is enabled and your account has Vertex AI permissions.\n"
   ],
   "id": "7283f0ba39308353",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Config (LLMs, Embeddings, Vector Store, Data Loader)\n",
    "\n",
    "import os\n",
    "\n",
    "# DataLoader Config\n",
    "query_terms = [\n",
    "    \"Interstate 81\",\n",
    "    \"Shenandoah Valley\",\n",
    "    \"Roanoke\",\n",
    "    \"Appalachian Mountains\",\n",
    "]  # fallback if WIKIPEDIA_QUERY is unset\n",
    "\n",
    "wiki_query = os.environ.get(\"WIKIPEDIA_QUERY\", \"\").strip() or \" OR \".join(query_terms)\n",
    "max_docs = int(os.environ.get(\"WIKIPEDIA_MAX_DOCS\", \"10\"))\n",
    "\n",
    "# Retriever Config\n",
    "k = int(os.environ.get(\"WIKIPEDIA_TOP_K\", \"3\"))\n",
    "EMBEDDING_MODEL = os.environ.get(\"VERTEX_EMBEDDING_MODEL\", \"text-embedding-005\")\n",
    "\n",
    "# LLM Config\n",
    "LLM_MODEL_NAME = os.environ.get(\"VERTEX_LLM_MODEL\", \"gemini-flash-latest\")\n",
    "\n",
    "# Vector store choice\n",
    "VECTORSTORE = os.environ.get(\"VECTORSTORE\", \"chroma\").lower()\n",
    "CHROMA_PERSIST_DIR = os.environ.get(\"CHROMA_PERSIST_DIR\", \"./.chroma\")\n",
    "\n",
    "example_question = \"What states does Interstate 81 run through?\"\n"
   ],
   "id": "a5c7760b7a531fa5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Wikipedia Data Loader\n",
    "\n",
    "docs = WikipediaLoader(query=wiki_query, load_max_docs=max_docs).load()\n",
    "\n",
    "print(f\"Loaded {len(docs)} docs for query: {wiki_query!r}\")\n"
   ],
   "id": "8c06ca8d46087871",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Retriever: Vector store + Vertex AI embeddings\n",
    "\n",
    "embeddings = VertexAIEmbeddings(model_name=EMBEDDING_MODEL)\n",
    "\n",
    "if VECTORSTORE == \"faiss\":\n",
    "    if not _HAS_FAISS:\n",
    "        raise RuntimeError(\n",
    "            \"FAISS requested but not available. Install it with: python -m pip install -r requirements-faiss.txt\"\n",
    "        )\n",
    "    vector_store = FAISS.from_documents(docs, embeddings)\n",
    "else:\n",
    "    vector_store = Chroma.from_documents(\n",
    "        docs,\n",
    "        embeddings,\n",
    "        persist_directory=CHROMA_PERSIST_DIR,\n",
    "        collection_name=\"agentic-wikipedia\",\n",
    "    )\n",
    "\n",
    "results = vector_store.similarity_search(example_question, k=k)\n",
    "for res in results:\n",
    "    title = res.metadata.get(\"title\", \"(no title)\")\n",
    "    preview = res.page_content.replace(\"\\n\", \" \")[:220]\n",
    "    print(f\"* {title}: {preview}…\")\n"
   ],
   "id": "810b89d3a63e7db1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# LLM: Using Vertex AI Foundation Model\n",
    "\n",
    "llm = ChatVertexAI(model_name=LLM_MODEL_NAME)\n",
    "response = llm.invoke(example_question)\n",
    "print(response.content)\n",
    "\n",
    "# Note: this is a direct LLM call (not RAG). Use the retrieved docs above to build a grounded prompt.\n"
   ],
   "id": "29146166add8439e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## a) GenAI Application Development\n",
    "\n",
    "**REQUIRED**: This section is where you input your custom logic to create and run your agentic workflow. Feel free to add as many code cells as needed.\n",
    "\n",
    "\n"
   ],
   "id": "bccee10d62a50f78"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# TODO: Enter your Agentic workflow code here",
   "id": "77559b480ff3442",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## b) Reflection\n",
    "\n",
    "**REQUIRED**: Provide a detailed reflection addressing these two questions:\n",
    "1. If you had more time, which specific improvements or enhancements would you make to your agentic workflow, and why?\n",
    "2. What concrete steps are required to move this workflow from prototype to production?\n",
    "\n",
    "> Enter your reflection here\n"
   ],
   "id": "1aca95bf050b4543"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T19:32:04.897380Z",
     "start_time": "2026-01-31T19:32:04.863079Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "## Vertex AI Checklist (Pre-Run)\n",
    "\n",
    "- Confirm your project is correct and billing is enabled.\n",
    "- Enable `aiplatform.googleapis.com`.\n",
    "- Ensure the notebook service account has `Vertex AI User` and `Service Account User` roles.\n",
    "- Verify model availability in your region (Gemini + Embeddings).\n",
    "- Check quotas for embedding and LLM calls.\n",
    "- Keep `max_docs` small for the first run and scale gradually.\n",
    "- Note expected costs for embeddings and model usage."
   ],
   "id": "b62d5b5c69600eb1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T19:31:05.510853Z",
     "start_time": "2026-01-31T19:31:05.502845Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "## Primers and Background to Explore (Internet Research)\n",
    "\n",
    "- Vertex AI authentication patterns (local vs. managed notebooks).\n",
    "- LangChain + Vertex AI integration guide.\n",
    "- Wikipedia API usage limits and best practices.\n",
    "- Vector search fundamentals: embeddings, cosine similarity, FAISS indexing types.\n",
    "- Retrieval-Augmented Generation (RAG) design patterns.\n",
    "- LangGraph basics and agentic workflow orchestration.\n",
    "- Prompt engineering for grounding and citation safety.\n"
   ],
   "id": "a04783209fb435cd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-31T19:31:05.519978Z",
     "start_time": "2026-01-31T19:31:05.515354Z"
    }
   },
   "cell_type": "markdown",
   "source": [
    "## Alternatives and Discussion Items\n",
    "\n",
    "- **Vector stores**: Vertex AI Vector Search, ChromaDB, Weaviate, Pinecone, or Qdrant.\n",
    "- **Embeddings**: OpenAI embeddings, Hugging Face sentence-transformers, or ertex AI text embeddings.\n",
    "- **LLMs**: Gemini variants, open-source LLMs (e.g., Llama), or hosted APIs.\n",
    "- **Retrievers**: hybrid search (BM25 + embeddings), rerankers, or multi-vector approaches.\n",
    "- **Agent frameworks**: LangGraph, LangChain Agents, Semantic Kernel, or custom orchestration.\n",
    "- **Evaluation**: How you will measure retrieval accuracy and answer quality (golden sets, human review).\n",
    "- **Safety and grounding**: How to handle hallucinations, citations, and source validation.\n"
   ],
   "id": "b4664ef6999a479d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Incremental Build Plan (Suggested)\n",
    "\n",
    "1. Validate Vertex AI authentication and model calls with a tiny prompt.\n",
    "2. Load a very small set of Wikipedia articles (e.g., 5–10).\n",
    "3. Build embeddings and run a simple similarity search.\n",
    "4. Add LLM response that cites retrieved documents.\n",
    "5. Implement a basic agentic workflow (single tool + loop).\n",
    "6. Add evaluation checks and reflection notes after each stage."
   ],
   "id": "d0bdd14e39f8ad99"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
